{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93254332",
   "metadata": {},
   "source": [
    "# Synthetic Hawkes Calibration\n",
    "\n",
    "Benchmark classical and neural Hawkes models on synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969de591",
   "metadata": {},
   "source": [
    "## 1. Generate synthetic sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a9c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import neural_hawkes as nh\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "synthetic_cfg = dict(num_sequences=200, num_events=400, num_types=4, seed=42)\n",
    "sequences = nh.generate_synthetic_sequences(**synthetic_cfg)\n",
    "dataset = nh.EventSequenceDataset(sequences, window_size=64, stride=32)\n",
    "train_set, val_set, test_set = nh.split_dataset(dataset, (0.7, 0.15, 0.15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076a50a8",
   "metadata": {},
   "source": [
    "## 2. Classical Hawkes baseline (tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a4f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    from tick.hawkes import HawkesExpKern\n",
    "    times = [seq.times for seq in sequences]\n",
    "    learner = HawkesExpKern(decays=2.0)\n",
    "    learner.fit(times)\n",
    "    print('Classical Hawkes fitted:')\n",
    "    print('mu =', learner.baseline)\n",
    "    print('adjacency =', learner.adjacency)\n",
    "except Exception as exc:\n",
    "    print('tick not available or fit failed:', exc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fbea2d",
   "metadata": {},
   "source": [
    "## 3. Neural Hawkes training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6606d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "collate = nh.collate_windows\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, collate_fn=collate)\n",
    "val_loader = DataLoader(val_set, batch_size=256, shuffle=False, collate_fn=collate)\n",
    "test_loader = DataLoader(test_set, batch_size=256, shuffle=False, collate_fn=collate)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = nh.NeuralHawkesModel(num_types=4, embed_dim=32, hidden_dim=64, backbone='gru').to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "history = []\n",
    "for epoch in range(1, 6):\n",
    "    train_metrics = nh.train_one_epoch(model, train_loader, optim, device, delta_weight=1.0)\n",
    "    val_metrics = nh.evaluate(model, val_loader, device, delta_weight=1.0)\n",
    "    history.append((train_metrics, val_metrics))\n",
    "    print(f\"Epoch {epoch}: train {train_metrics['loss']:.4f}, val {val_metrics['loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4213c392",
   "metadata": {},
   "source": [
    "## 4. Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b2dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_deltas, true_deltas, mask = nh.collect_predictions(model, test_loader, device)\n",
    "diag = nh.time_rescaling_diagnostics(pred_deltas, true_deltas, mask)\n",
    "diag\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
