{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbad8def",
   "metadata": {},
   "source": [
    "# Binance Hawkes Calibration\n",
    "\n",
    "Calibrate Hawkes models on Binance BTCUSDT trades preprocessed via `scripts/preprocess_binance.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ade94e",
   "metadata": {},
   "source": [
    "## 1. Load processed sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import neural_hawkes as nh\n",
    "\n",
    "processed_dir = Path('data/runs/events')\n",
    "combined_times = np.load(processed_dir / 'BTCUSDT-2025-09-21-combined-times.npy')\n",
    "combined_marks = np.load(processed_dir / 'BTCUSDT-2025-09-21-combined-marks.npy')\n",
    "\n",
    "sequence = nh.EventSequence(times=combined_times, types=combined_marks)\n",
    "sequences = [sequence]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee219d0d",
   "metadata": {},
   "source": [
    "## 2. Classical Hawkes (tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edf15c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    from tick.hawkes import HawkesExpKern\n",
    "    learner = HawkesExpKern(decays=2.0)\n",
    "    learner.fit([sequence.times])\n",
    "    print('mu =', learner.baseline)\n",
    "    print('adjacency =', learner.adjacency)\n",
    "except Exception as exc:\n",
    "    print('tick not available or fit failed:', exc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb80ab0",
   "metadata": {},
   "source": [
    "## 3. Neural Hawkes training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c311dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = nh.EventSequenceDataset(sequences, window_size=64, stride=32)\n",
    "train_set, val_set, test_set = nh.split_dataset(dataset, (0.7, 0.15, 0.15))\n",
    "collate = nh.collate_windows\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "val_loader = DataLoader(val_set, batch_size=64, shuffle=False, collate_fn=collate)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False, collate_fn=collate)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = nh.NeuralHawkesModel(num_types=2, embed_dim=32, hidden_dim=64, backbone='gru').to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, 4):\n",
    "    train_metrics = nh.train_one_epoch(model, train_loader, optim, device, delta_weight=1.0)\n",
    "    val_metrics = nh.evaluate(model, val_loader, device, delta_weight=1.0)\n",
    "    print(f\"Epoch {epoch}: train {train_metrics['loss']:.4f}, val {val_metrics['loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd43c6",
   "metadata": {},
   "source": [
    "## 4. Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b04d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_deltas, true_deltas, mask = nh.collect_predictions(model, test_loader, device)\n",
    "nh.time_rescaling_diagnostics(pred_deltas, true_deltas, mask)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
